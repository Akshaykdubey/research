import numpy as np
from numpy import  arange
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D


# To read data from
def get_data(path):
    auto_mpg_data = pd.read_csv(path, header=None, delimiter=r"\s+")
    raw_mpg_data = auto_mpg_data.iloc[:, [0, 2, 5]]

    # Normalize the input data
    normalized_data = (raw_mpg_data - raw_mpg_data.mean()) / raw_mpg_data.std()

    acceleration = normalized_data.iloc[:,[1]].values  # [ slice_of_rows, slice_of_columns ]
    displacement = normalized_data.iloc[:,[2]].values  # [ slice_of_rows, slice_of_columns ]
    mpg = normalized_data.iloc[:,[0]].values  # [ slice_of_rows, slice_of_columns ]

    return acceleration, displacement, mpg, normalized_data


# To calculate error
def mean_square_error(x, y, theta_val):
    sum_j = np.power(x * theta_val.T - y, 2)
    return np.sum(sum_j) / (2 * len(x))  # Returns the computed mean square error


# Compute coefficients using gradient descent algorithm
def gradient_descent(X, y, learning_rate, num_iterations):
    X = np.matrix(X)
    num_parameters = X.shape[1]  # dim theta
    theta = np.matrix([0.0 for i in range(num_parameters)])  # init theta
    cost = [0.0 for i in range(num_iterations)]

    for it in range(num_iterations):
        error = np.repeat((X * theta.T) - y, num_parameters, axis=1)
        error_derivative = np.sum(np.multiply(error, X), axis=0)
        theta = theta - (learning_rate / len(y)) * error_derivative
        cost[it] = mean_square_error(X, y, theta)

    return theta, cost


acc_val, dis_val, mpg_val, auto_mpg_input = get_data("https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data")
iterations = 10
alpha = 0.10

X_input = auto_mpg_input.iloc[:, [1,2]]  # Contains acceleration and displacement as part of input
y_input = auto_mpg_input.iloc[:, [0]]  # Contains mpg as the response

theta, cost = gradient_descent(X_input, y_input, alpha, iterations)  # Returns value of theta and cost
print("The parameters : ")
print('Theta: ', theta)
print('Cost function: ', cost)

# Plot the 3-D graph
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
for c, m, zl, zh in [('r', 'o', -50, -25)]:
    xs = acc_val
    ys = dis_val
    zs = mpg_val
    ax.scatter(xs, ys, zs, c=c, marker=m)
ax.set_xlabel('Displacement')
ax.set_ylabel('Acceleration')
ax.set_zlabel('mpg')
plt.title('3-D projection of Acceleration, Displacement and Mpg')
plt.savefig('MpgData.png'); plt.savefig('MpgData.pdf')
plt.show()

# Plotting graph between iterations and cost to demonstrate decline in error.
plt.plot(arange(iterations), cost)
plt.title('Graph to show decrease in convergence as number of iteration grows')
plt.xlabel('Iterations')
plt.ylabel('Cost Function')
plt.show()
